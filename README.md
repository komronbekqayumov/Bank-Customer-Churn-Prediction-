
---

## ğŸ§  Customer Churn Prediction

This project focuses on predicting **customer churn** using supervised machine learning algorithms. The dataset is preprocessed, enhanced with feature engineering, and evaluated across multiple models to identify the most accurate predictor.

---

### ğŸ“‚ Project Structure

```
â”œâ”€â”€ dataset.csv
â”œâ”€â”€ churn_prediction.ipynb
â”œâ”€â”€ final_predictions.csv
â”œâ”€â”€ models.pkl
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

### ğŸ›  Technologies Used

* Python
* Pandas, NumPy
* Scikit-learn
* XGBoost
* LightGBM
* Matplotlib, Seaborn
* Jupyter Notebook (Kaggle Environment)

---

### ğŸ”„ Workflow

1. **Data Preprocessing**

   * Handled missing values
   * Encoded categorical variables (LabelEncoding, OneHotEncoding)

2. **Feature Engineering**

   * Created new features such as `AgeBalanceRatio`, `IsSenior`, `HasHighBalance`, `ProductsPerYear`, and others to boost model performance

3. **Model Training & Evaluation**
   Models used:

   * Logistic Regression
   * Random Forest
   * XGBoost
   * LightGBM
   * K-Nearest Neighbors (KNN)
   * Support Vector Machine (SVM)

4. **Model Selection**

   * Accuracy scores were compared, and the best-performing model was identified

---

### âœ… Results

```text
Logistic Regression         â†’ Accuracy: 88.57%
Random Forest               â†’ Accuracy: 89.73%
XGBoost                     â†’ Accuracy: 89.50%
LightGBM                    â†’ Accuracy: 89.93%
K-Nearest Neighbors (KNN)   â†’ Accuracy: 87.47%
Support Vector Machine (SVM) â†’ Accuracy: 89.27%


ğŸ¯ Best Model: Random Forest Classifier  
âœ”ï¸ Accuracy: 89.73%
```

---



For questions or suggestions, feel free to open an issue or contact me via GitHub.

---

